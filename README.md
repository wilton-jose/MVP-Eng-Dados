# **MVP Engenharia de Dados - AnÃ¡lise do Consumo de Energia no Brasil (2018-2020)**  

**Autor:** [Wilton JosÃ© da Silva JÃºnior](https://github.com/wilton-jose)  
**InstituiÃ§Ã£o:** PUC-RIO  

## **ğŸ“Œ VisÃ£o Geral**  

Este projeto tem como objetivo analisar o consumo de energia elÃ©trica no Brasil entre 2018 e 2020, utilizando dados pÃºblicos da **CCEE (CÃ¢mara de ComercializaÃ§Ã£o de Energia ElÃ©trica)**. O pipeline de dados foi construÃ­do em um ambiente **Databricks**, seguindo a arquitetura **Lakehouse (Bronze â†’ Silver â†’ Gold)** e implementando um modelo **Star Schema** para anÃ¡lise dimensional.  

ğŸ”¹ **Principais perguntas respondidas:**  
âœ” Como o consumo varia por regiÃ£o/estado ao longo do ano?  
âœ” Quais ramos de atividade tÃªm os maiores consumos?  
âœ” Existem padrÃµes sazonais significativos no consumo?  
âœ” Quais estados apresentam maior crescimento no consumo?  

---

## **ğŸ“‚ Estrutura do Projeto**  

### **ğŸ¯ Objetivos**  
- Construir um pipeline de dados escalÃ¡vel para ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise.  
- Identificar tendÃªncias e padrÃµes no consumo de energia por estado, ramo de atividade e perÃ­odo.  
- Gerar insights para otimizaÃ§Ã£o da distribuiÃ§Ã£o energÃ©tica.  

### **ğŸ“Š Arquitetura do Pipeline**  

| **Camada**  | **DescriÃ§Ã£o** | **Tecnologias** |  
|-------------|--------------|----------------|  
| **Bronze**  | Dados brutos ingeridos da fonte (CSV) | Spark, Delta Lake |  
| **Silver**  | Dados limpos, modelados em esquema estrela | Spark SQL, Delta Lake |  
| **Gold**    | AgregaÃ§Ãµes e anÃ¡lises prontas para visualizaÃ§Ã£o | Spark SQL, Delta Lake |  

### **ğŸ“‹ Modelagem de Dados**  

#### **Bronze (`bronze_cmee_br`)**  
- Armazena os dados brutos da CCEE.  
- Inclui metadados como `ingestion_date` e `file_name`.  

#### **Silver (Esquema Estrela)**  
- **Tabelas de dimensÃ£o:** `dim_data`, `dim_classe`, `dim_ramo`, `dim_submercado`, `dim_estado`  
- **Tabela fato:** `fato_consumo`  

#### **Gold (AnÃ¡lises Prontas)**  
- `gold_consumo_por_estado`  
- `gold_tendencia_mensal`  
- `gold_top_ramos`  
- `gold_tendencia_mensal_avancada`  

---

## **âš™ï¸ Tecnologias Utilizadas**  

- **Apache Spark** (ETL e processamento distribuÃ­do)  
- **Delta Lake** (Armazenamento em Lakehouse)  
- **Databricks** (Plataforma de execuÃ§Ã£o)  
- **Python** (AnÃ¡lise e visualizaÃ§Ã£o)  
- **Matplotlib/Seaborn** (GrÃ¡ficos)  

---

## **ğŸ“ˆ Principais Insights**  

### **1ï¸âƒ£ Consumo por Estado**  
- **SÃ£o Paulo (SP)** lidera em consumo total (**9,6M MWm**).  
- **Acre (AC)** tem o menor consumo (**72K MWm**).  

### **2ï¸âƒ£ TendÃªncia Mensal**  
- **Pico em janeiro** (alta demanda no verÃ£o).  
- **Queda em junho** (clima mais ameno).  

### **3ï¸âƒ£ Ramos com Maior Consumo**  
1. **ACR (Ambiente de ContrataÃ§Ã£o Regulada)** â†’ **25,2M MWm**  
2. **Metalurgia** â†’ **2,7M MWm**  
3. **QuÃ­micos** â†’ **1,1M MWm**  

---

## **ğŸš€ Como Executar o Projeto**  

1. **Configurar o ambiente Databricks:**  
   - Criar um cluster com **Apache Spark 3.x**.  
   - Configurar acesso ao **DBFS (Databricks File System)**.  

2. **Importar os notebooks:**  
   - DisponÃ­veis em: [MVP-Eng-Dados](https://github.com/wilton-jose/MVP-Eng-Dados)  

3. **Executar o pipeline:**  
   - Rodar os notebooks na ordem:  
     - `1_Ingestao_Bronze`  
     - `2_Processamento_Silver`  
     - `3_Analise_Gold`  

4. **Visualizar resultados:**  
   - Dashboards no Databricks ou exportar para Power BI/Tableau.  

---

## **ğŸ“Œ PrÃ³ximos Passos**  

âœ… **Adicionar dados meteorolÃ³gicos** para correlacionar clima e consumo.  
âœ… **Criar um dashboard interativo** com filtros por perÃ­odo e regiÃ£o.  
âœ… **Automatizar o pipeline** com agendamento (Airflow/Databricks Jobs).  

---

## **ğŸ“œ LicenÃ§a**  
Este projeto utiliza dados pÃºblicos da **CCEE**. Consulte as polÃ­ticas de uso em: [CCEE Dados Abertos](https://www.ccee.org.br/dados-abertos)  

---

**ğŸ”— RepositÃ³rio:** [GitHub - MVP Engenharia de Dados](https://github.com/wilton-jose/MVP-Eng-Dados)  
